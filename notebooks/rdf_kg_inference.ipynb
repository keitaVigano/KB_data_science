{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ds: <http://example.org/ds#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ds:authored rdfs:domain ds:Author ;\n",
      "    rdfs:range ds:Paper ;\n",
      "    owl:inverseOf ds:hasAuthor .\n",
      "\n",
      "<http://example.org/ds/0000-0001-9601-0403> a ds:Author ;\n",
      "    rdfs:label \"Mirko Cesarini\" ;\n",
      "    ds:fullName \"Mirko Cesarini\" ;\n",
      "    ds:hasDSDepartment 1 ;\n",
      "    ds:hasHIndex 15 ;\n",
      "    ds:hasInstitution <https://openalex.org/I66752286> ;\n",
      "    ds:hasInstitutionID \"https://openalex.org/I66752286\" ;\n",
      "    ds:hasORCID \"0000-0001-9601-0403\" ;\n",
      "    ds:hasOpenAlexID \"https://openalex.org/A5049259722\" ;\n",
      "    ds:hasSSD \"ING-INF/05\" ;\n",
      "    ds:hasTopic \"['Data Quality and Management', 'Semantic Web and Ontologies', 'Data Mining Algorithms and Applications', 'Privacy-Preserving Technologies in Data', 'Advanced Database Systems and Queries', 'Service-Oriented Architecture and Web Services', 'Big Data and Business Intelligence', 'Web Data Mining and Analysis', 'Business Strategy and Innovation', 'Business Process Modeling and Analysis', 'E-Government and Public Services', 'Management, Economics, and Public Policy', 'Advanced Graph Neural Networks', 'Recommender Systems and Techniques', 'Complex Network Analysis Techniques', 'Graph Theory and Algorithms', 'E-Learning and Knowledge Management', 'Access Control and Trust', 'Text and Document Classification Technologies', 'Internet Traffic Analysis and Secure E-voting', 'Open Education and E-Learning', 'Sentiment Analysis and Opinion Mining', 'Legal and Labor Studies', 'Digital and Cyber Forensics', 'Mobile Agent-Based Network Management']\" ;\n",
      "    ds:pastInstitutionsID \"['https://openalex.org/I4210135780', 'https://openalex.org/I30771326', 'https://openalex.org/I189158943', 'https://openalex.org/I93860229']\" ;\n",
      "    ds:teaches <http://example.org/ds/Service_Science> .\n",
      "\n",
      "<http://example.org/ds/0000-0003-2461-275X> a ds:Author ;\n",
      "    rdfs:label \"Marco Paganoni\" ;\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "# Carica i dati\n",
    "df_authors = pd.read_csv('../data/authors/authors_final.csv')\n",
    "df_courses = pd.read_csv('../data/courses/courses.csv')\n",
    "\n",
    "# Inizializza grafo RDF\n",
    "g = Graph()\n",
    "DS = Namespace(\"http://example.org/ds#\")\n",
    "g.bind(\"ds\", DS)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "\n",
    "# Mappa ORCID → info autore\n",
    "author_info = {\n",
    "    str(row['orcid']).strip(): row for _, row in df_authors.iterrows()\n",
    "}\n",
    "\n",
    "# Aggiungi corsi e relazioni autore-corso\n",
    "for _, row in df_courses.iterrows():\n",
    "    course_name = row['Course']\n",
    "    course_id = course_name.replace(' ', '_')\n",
    "    course_uri = URIRef(f\"http://example.org/ds/{course_id}\")\n",
    "\n",
    "    g.add((course_uri, RDF.type, DS.Course))\n",
    "    g.add((course_uri, DS.courseName, Literal(course_name)))\n",
    "    g.add((course_uri, RDFS.label, Literal(course_name)))\n",
    "\n",
    "    # Parsa lista di ORCID\n",
    "    try:\n",
    "        orcid_list = ast.literal_eval(row['orcid'])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Errore parsing ORCID per '{course_name}': {e}\")\n",
    "        continue\n",
    "\n",
    "    for orcid in orcid_list:\n",
    "        orcid = orcid.strip().replace('\"', '').replace(\"'\", \"\")\n",
    "        author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "        \n",
    "        # Base autore\n",
    "        g.add((author_uri, RDF.type, DS.Author))\n",
    "        g.add((author_uri, DS.hasORCID, Literal(orcid)))\n",
    "        g.add((author_uri, DS.teaches, course_uri))\n",
    "\n",
    "        # Arricchimento se info presente\n",
    "        if orcid in author_info:\n",
    "            info = author_info[orcid]\n",
    "            name = str(info['Name'])\n",
    "\n",
    "            g.add((author_uri, DS.fullName, Literal(name)))\n",
    "            g.add((author_uri, RDFS.label, Literal(name)))  # Mostrato nei tool\n",
    "\n",
    "            if pd.notna(info['SSD']):\n",
    "                g.add((author_uri, DS.hasSSD, Literal(info['SSD'])))\n",
    "\n",
    "            if pd.notna(info['hindex']):\n",
    "                g.add((author_uri, DS.hasHIndex, Literal(int(info['hindex']), datatype=XSD.integer)))\n",
    "\n",
    "            if pd.notna(info['openalex id']):\n",
    "                g.add((author_uri, DS.hasOpenAlexID, Literal(info['openalex id'])))\n",
    "\n",
    "            if pd.notna(info['topics']):\n",
    "                g.add((author_uri, DS.hasTopic, Literal(info['topics'])))\n",
    "\n",
    "            if pd.notna(info['past_institutions_id']):\n",
    "                g.add((author_uri, DS.pastInstitutionsID, Literal(info['past_institutions_id'])))\n",
    "\n",
    "            if pd.notna(info['DS Department']):\n",
    "                g.add((author_uri, DS.hasDSDepartment, Literal(info['DS Department'])))\n",
    "\n",
    "            if pd.notna(info['ins_id']):\n",
    "                g.add((author_uri, DS.hasInstitutionID, Literal(info['ins_id'])))\n",
    "        else:\n",
    "            print(f\"⚠️ ORCID non trovato in df_authors: {orcid}\")\n",
    "        \n",
    "    # STEP FINALE: aggiungi autori non presenti tra gli insegnanti\n",
    "    for orcid, info in author_info.items():\n",
    "        orcid = orcid.strip()\n",
    "        author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "\n",
    "        # Se autore non ha nessuna tripla ds:teaches → aggiungilo ora\n",
    "        if (author_uri, DS.teaches, None) not in g:\n",
    "            g.add((author_uri, RDF.type, DS.Author))\n",
    "            g.add((author_uri, DS.hasORCID, Literal(orcid)))\n",
    "            name = str(info['Name'])\n",
    "            g.add((author_uri, DS.fullName, Literal(name)))\n",
    "            g.add((author_uri, RDFS.label, Literal(name)))\n",
    "\n",
    "            if pd.notna(info['SSD']):\n",
    "                g.add((author_uri, DS.hasSSD, Literal(info['SSD'])))\n",
    "\n",
    "            if pd.notna(info['hindex']):\n",
    "                g.add((author_uri, DS.hasHIndex, Literal(int(info['hindex']), datatype=XSD.integer)))\n",
    "\n",
    "            if pd.notna(info['openalex id']):\n",
    "                g.add((author_uri, DS.hasOpenAlexID, Literal(info['openalex id'])))\n",
    "\n",
    "            if pd.notna(info['topics']):\n",
    "                g.add((author_uri, DS.hasTopic, Literal(info['topics'])))\n",
    "\n",
    "            if pd.notna(info['past_institutions_id']):\n",
    "                g.add((author_uri, DS.pastInstitutionsID, Literal(info['past_institutions_id'])))\n",
    "\n",
    "            if pd.notna(info['DS Department']):\n",
    "                g.add((author_uri, DS.hasDSDepartment, Literal(info['DS Department'])))\n",
    "\n",
    "            if pd.notna(info['ins_id']):\n",
    "                g.add((author_uri, DS.hasInstitutionID, Literal(info['ins_id'])))\n",
    "            \n",
    "# --- Aggiunta dei paper al grafo ---\n",
    "df_papers = pd.read_csv('../data/papers/papers.csv')  # adatta il path\n",
    "\n",
    "for _, row in df_papers.iterrows():\n",
    "    if pd.isna(row['doi']):\n",
    "        continue\n",
    "\n",
    "    doi = row['doi'].strip()\n",
    "    paper_uri = URIRef(f\"http://example.org/ds/paper/{doi.replace('/', '_')}\")\n",
    "\n",
    "    g.add((paper_uri, RDF.type, DS.Paper))\n",
    "    g.add((paper_uri, DS.hasDOI, Literal(doi)))\n",
    "    g.add((paper_uri, DS.hasTitle, Literal(row['title'])))\n",
    "    g.add((paper_uri, DS.hasYear, Literal(int(row['year']), datatype=XSD.gYear)))\n",
    "    g.add((paper_uri, DS.hasType, Literal(row['type'])))\n",
    "    g.add((paper_uri, DS.hasTopic, Literal(row['topics'])))\n",
    "\n",
    "    # Associa autori via ORCID\n",
    "    try:\n",
    "        orcid_list = ast.literal_eval(row['author_orcids'])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Errore parsing ORCID in paper {doi}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for orcid in orcid_list:\n",
    "        if orcid is None or pd.isna(orcid):\n",
    "            continue\n",
    "        orcid = orcid.strip()\n",
    "        author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "        g.add((paper_uri, DS.hasAuthor, author_uri))\n",
    "        g.add((author_uri, DS.authored, paper_uri))  # relazione inversa opzionale\n",
    "\n",
    "# --- Aggiunta delle istituzioni e collegamento agli autori ---\n",
    "df_institutions = pd.read_csv('../data/institution/institutions.csv')  # adatta path\n",
    "\n",
    "# Mappa ID → dati istituzione\n",
    "institution_info = {\n",
    "    str(row['ins_id']).strip(): row for _, row in df_institutions.iterrows()\n",
    "}\n",
    "\n",
    "# Aggiungi istituzioni al grafo\n",
    "for ins_id, row in institution_info.items():\n",
    "    inst_uri = URIRef(ins_id)  # usiamo direttamente l'URI di OpenAlex\n",
    "    g.add((inst_uri, RDF.type, DS.Institution))\n",
    "    g.add((inst_uri, DS.institutionName, Literal(row['ins_name'])))\n",
    "    g.add((inst_uri, DS.institutionType, Literal(row['ins_type'])))\n",
    "    g.add((inst_uri, DS.institutionCountry, Literal(row['ins_country'])))\n",
    "    g.add((inst_uri, RDFS.label, Literal(row['ins_name'])))\n",
    "\n",
    "# Collega autori alle istituzioni (se l'ins_id esiste)\n",
    "for orcid, info in author_info.items():\n",
    "    orcid = orcid.strip()\n",
    "    author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "    ins_id = str(info['ins_id']).strip()\n",
    "\n",
    "    if ins_id in institution_info:\n",
    "        inst_uri = URIRef(ins_id)\n",
    "        g.add((author_uri, DS.hasInstitution, inst_uri))\n",
    "\n",
    "from rdflib.namespace import RDF, RDFS, XSD, OWL\n",
    "\n",
    "# Class hierarchy\n",
    "g.add((DS.Author, RDFS.subClassOf, DS.Person))\n",
    "\n",
    "# Property domains and ranges\n",
    "g.add((DS.authored, RDFS.domain, DS.Author))\n",
    "g.add((DS.authored, RDFS.range, DS.Paper))\n",
    "\n",
    "g.add((DS.hasAuthor, RDFS.domain, DS.Paper))\n",
    "g.add((DS.hasAuthor, RDFS.range, DS.Author))\n",
    "\n",
    "# Proprietà inverse (non automatiche in RDFS)\n",
    "g.add((DS.authored, OWL.inverseOf, DS.hasAuthor))\n",
    "\n",
    "from rdflib import Graph, URIRef\n",
    "from rdflib.namespace import OWL\n",
    "import pandas as pd\n",
    "\n",
    "# Carica il dataset (modifica il percorso se necessario)\n",
    "df = pd.read_csv(\"../data/institution/institutions_wiki.csv\")\n",
    "\n",
    "# Inizializza il grafo RDF\n",
    "g \n",
    "\n",
    "# Aggiungi solo le triple owl:sameAs se wikidata_id è presente\n",
    "for _, row in df.iterrows():\n",
    "    wikidata_id = row.get(\"wikidata_id\")\n",
    "    if pd.notna(wikidata_id) and wikidata_id.strip() != \"\":\n",
    "        openalex_uri = URIRef(row[\"ins_id\"].strip())\n",
    "        wikidata_uri = URIRef(wikidata_id.strip())\n",
    "        g.add((openalex_uri, OWL.sameAs, wikidata_uri))\n",
    "# Esporta in Turtle\n",
    "ttl_output = g.serialize(format=\"turtle\")\n",
    "print(ttl_output[:2000])  # Anteprima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ds: <http://example.org/ds#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "ds:authored rdfs:domain ds:Author ;\n",
      "    rdfs:range ds:Paper ;\n",
      "    owl:inverseOf ds:hasAuthor .\n",
      "\n",
      "<http://example.org/ds/0000-0001-9601-0403> a ds:Author ;\n",
      "    rdfs:label \"Mirko Cesarini\" ;\n",
      "    ds:fullName \"Mirko Cesarini\" ;\n",
      "    ds:hasDSDepartment 1 ;\n",
      "    ds:hasHIndex 15 ;\n",
      "    ds:hasInstitution <https://openalex.org/I66752286> ;\n",
      "    ds:hasInstitutionID \"https://openalex.org/I66752286\" ;\n",
      "    ds:hasORCID \"0000-0001-9601-0403\" ;\n",
      "    ds:hasOpenAlexID \"https://openalex.org/A5049259722\" ;\n",
      "    ds:hasSSD \"ING-INF/05\" ;\n",
      "    ds:hasTopic \"['Data Quality and Management', 'Semantic Web and Ontologies', 'Data Mining Algorithms and Applications', 'Privacy-Preserving Technologies in Data', 'Advanced Database Systems and Queries', 'Service-Oriented Architecture and Web Services', 'Big Data and Business Intelligence', 'Web Data Mining and Analysis', 'Business Strategy and Innovation', 'Business Process Modeling and Analysis', 'E-Government and Public Services', 'Management, Economics, and Public Policy', 'Advanced Graph Neural Networks', 'Recommender Systems and Techniques', 'Complex Network Analysis Techniques', 'Graph Theory and Algorithms', 'E-Learning and Knowledge Management', 'Access Control and Trust', 'Text and Document Classification Technologies', 'Internet Traffic Analysis and Secure E-voting', 'Open Education and E-Learning', 'Sentiment Analysis and Opinion Mining', 'Legal and Labor Studies', 'Digital and Cyber Forensics', 'Mobile Agent-Based Network Management']\" ;\n",
      "    ds:pastInstitutionsID \"['https://openalex.org/I4210135780', 'https://openalex.org/I30771326', 'https://openalex.org/I189158943', 'https://openalex.org/I93860229']\" ;\n",
      "    ds:teaches <http://example.org/ds/Service_Science> .\n",
      "\n",
      "<http://example.org/ds/0000-0003-2461-275X> a ds:Author ;\n",
      "    rdfs:label \"Marco Paganoni\" ;\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD, OWL\n",
    "\n",
    "# === Caricamento dati ===\n",
    "df_authors = pd.read_csv('../data/authors/authors_final.csv')\n",
    "df_courses = pd.read_csv('../data/courses/courses.csv')\n",
    "df_papers = pd.read_csv('../data/papers/papers.csv')\n",
    "df_wiki = pd.read_csv('../data/institution/institutions_wiki.csv')\n",
    "\n",
    "# === Inizializza grafo ===\n",
    "g = Graph()\n",
    "DS = Namespace(\"http://example.org/ds#\")\n",
    "g.bind(\"ds\", DS)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"owl\", OWL)\n",
    "\n",
    "# === Mappa ORCID → info autore ===\n",
    "author_info = {\n",
    "    str(row['orcid']).strip(): row for _, row in df_authors.iterrows()\n",
    "}\n",
    "\n",
    "# === Aggiungi corsi e relazioni con autori ===\n",
    "for _, row in df_courses.iterrows():\n",
    "    course_name = row['Course']\n",
    "    course_id = course_name.replace(' ', '_')\n",
    "    course_uri = URIRef(f\"http://example.org/ds/{course_id}\")\n",
    "    g.add((course_uri, RDF.type, DS.Course))\n",
    "    g.add((course_uri, DS.courseName, Literal(course_name)))\n",
    "    g.add((course_uri, RDFS.label, Literal(course_name)))\n",
    "\n",
    "    try:\n",
    "        orcid_list = ast.literal_eval(row['orcid'])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Errore parsing ORCID per '{course_name}': {e}\")\n",
    "        continue\n",
    "\n",
    "    for orcid in orcid_list:\n",
    "        orcid = orcid.strip().replace('\"', '').replace(\"'\", \"\")\n",
    "        author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "        g.add((author_uri, RDF.type, DS.Author))\n",
    "        g.add((author_uri, DS.hasORCID, Literal(orcid)))\n",
    "        g.add((author_uri, DS.teaches, course_uri))\n",
    "\n",
    "        if orcid in author_info:\n",
    "            info = author_info[orcid]\n",
    "            g.add((author_uri, DS.fullName, Literal(info['Name'])))\n",
    "            g.add((author_uri, RDFS.label, Literal(info['Name'])))\n",
    "            if pd.notna(info['SSD']):\n",
    "                g.add((author_uri, DS.hasSSD, Literal(info['SSD'])))\n",
    "            if pd.notna(info['hindex']):\n",
    "                g.add((author_uri, DS.hasHIndex, Literal(int(info['hindex']), datatype=XSD.integer)))\n",
    "            if pd.notna(info['openalex id']):\n",
    "                g.add((author_uri, DS.hasOpenAlexID, Literal(info['openalex id'])))\n",
    "            if pd.notna(info['topics']):\n",
    "                g.add((author_uri, DS.hasTopic, Literal(info['topics'])))\n",
    "            if pd.notna(info['past_institutions_id']):\n",
    "                g.add((author_uri, DS.pastInstitutionsID, Literal(info['past_institutions_id'])))\n",
    "            if pd.notna(info['DS Department']):\n",
    "                g.add((author_uri, DS.hasDSDepartment, Literal(info['DS Department'])))\n",
    "            if pd.notna(info['ins_id']):\n",
    "                g.add((author_uri, DS.hasInstitutionID, Literal(info['ins_id'])))\n",
    "\n",
    "# === Aggiungi autori non docenti ===\n",
    "for orcid, info in author_info.items():\n",
    "    author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "    if (author_uri, DS.teaches, None) not in g:\n",
    "        g.add((author_uri, RDF.type, DS.Author))\n",
    "        g.add((author_uri, DS.hasORCID, Literal(orcid)))\n",
    "        g.add((author_uri, DS.fullName, Literal(info['Name'])))\n",
    "        g.add((author_uri, RDFS.label, Literal(info['Name'])))\n",
    "        if pd.notna(info['SSD']):\n",
    "            g.add((author_uri, DS.hasSSD, Literal(info['SSD'])))\n",
    "        if pd.notna(info['hindex']):\n",
    "            g.add((author_uri, DS.hasHIndex, Literal(int(info['hindex']), datatype=XSD.integer)))\n",
    "        if pd.notna(info['openalex id']):\n",
    "            g.add((author_uri, DS.hasOpenAlexID, Literal(info['openalex id'])))\n",
    "        if pd.notna(info['topics']):\n",
    "            g.add((author_uri, DS.hasTopic, Literal(info['topics'])))\n",
    "        if pd.notna(info['past_institutions_id']):\n",
    "            g.add((author_uri, DS.pastInstitutionsID, Literal(info['past_institutions_id'])))\n",
    "        if pd.notna(info['DS Department']):\n",
    "            g.add((author_uri, DS.hasDSDepartment, Literal(info['DS Department'])))\n",
    "        if pd.notna(info['ins_id']):\n",
    "            g.add((author_uri, DS.hasInstitutionID, Literal(info['ins_id'])))\n",
    "\n",
    "# === Aggiungi paper ===\n",
    "for _, row in df_papers.iterrows():\n",
    "    if pd.isna(row['doi']):\n",
    "        continue\n",
    "    doi = row['doi'].strip()\n",
    "    paper_uri = URIRef(f\"http://example.org/ds/paper/{doi.replace('/', '_')}\")\n",
    "    g.add((paper_uri, RDF.type, DS.Paper))\n",
    "    g.add((paper_uri, DS.hasDOI, Literal(doi)))\n",
    "    g.add((paper_uri, DS.hasTitle, Literal(row['title'])))\n",
    "    g.add((paper_uri, DS.hasYear, Literal(int(row['year']), datatype=XSD.gYear)))\n",
    "    g.add((paper_uri, DS.hasType, Literal(row['type'])))\n",
    "    g.add((paper_uri, DS.hasTopic, Literal(row['topics'])))\n",
    "\n",
    "    try:\n",
    "        orcid_list = ast.literal_eval(row['author_orcids'])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Errore parsing ORCID in paper {doi}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for orcid in orcid_list:\n",
    "        if orcid and pd.notna(orcid):\n",
    "            orcid = orcid.strip()\n",
    "            author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "            g.add((paper_uri, DS.hasAuthor, author_uri))\n",
    "            g.add((author_uri, DS.authored, paper_uri))\n",
    "\n",
    "# === Aggiungi istituzioni da df_wiki ===\n",
    "institution_info = {\n",
    "    str(row['ins_id']).strip(): row for _, row in df_wiki.iterrows()\n",
    "}\n",
    "\n",
    "for ins_id, row in institution_info.items():\n",
    "    inst_uri = URIRef(ins_id)\n",
    "    g.add((inst_uri, RDF.type, DS.Institution))\n",
    "    g.add((inst_uri, DS.institutionName, Literal(row['ins_name'])))\n",
    "    g.add((inst_uri, DS.institutionType, Literal(row['ins_type'])))\n",
    "    g.add((inst_uri, DS.institutionCountry, Literal(row['ins_country'])))\n",
    "    g.add((inst_uri, RDFS.label, Literal(row['ins_name'])))\n",
    "\n",
    "    if pd.notna(row['wikidata_id']) and row['wikidata_id'].strip():\n",
    "        wikidata_uri = URIRef(row['wikidata_id'].strip())\n",
    "        g.add((inst_uri, OWL.sameAs, wikidata_uri))\n",
    "\n",
    "# === Collega autori alle istituzioni (solo se ins_id è valido) ===\n",
    "for orcid, info in author_info.items():\n",
    "    author_uri = URIRef(f\"http://example.org/ds/{orcid}\")\n",
    "    ins_id = str(info['ins_id']).strip()\n",
    "    if ins_id in institution_info:\n",
    "        inst_uri = URIRef(ins_id)\n",
    "        g.add((author_uri, DS.hasInstitution, inst_uri))\n",
    "\n",
    "# === Ontologia base: proprietà e inverse ===\n",
    "g.add((DS.Author, RDFS.subClassOf, DS.Person))\n",
    "g.add((DS.authored, RDFS.domain, DS.Author))\n",
    "g.add((DS.authored, RDFS.range, DS.Paper))\n",
    "g.add((DS.hasAuthor, RDFS.domain, DS.Paper))\n",
    "g.add((DS.hasAuthor, RDFS.range, DS.Author))\n",
    "g.add((DS.authored, OWL.inverseOf, DS.hasAuthor))\n",
    "\n",
    "# === Serializza (anteprima) ===\n",
    "ttl_output = g.serialize(format=\"turtle\")\n",
    "print(ttl_output[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/knowledge_base2.ttl'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttl_path = \"../data/knowledge_base2.ttl\"\n",
    "g.serialize(destination=ttl_path, format=\"turtle\")\n",
    "\n",
    "ttl_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlrl import DeductiveClosure, OWLRL_Semantics\n",
    "from rdflib.namespace import OWL\n",
    "\n",
    "DeductiveClosure(OWLRL_Semantics).expand(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paola Rebora\n",
      "Davide Chicco\n",
      "Michele Ciavotta\n",
      "Andrea Maurino\n",
      "Elisabetta Fersini\n",
      "Enrico Moretto\n",
      "Paolo Napoletano\n",
      "Marco Viviani\n",
      "Marco Guerzoni\n",
      "Dario Pescini\n",
      "Matteo Palmonari\n",
      "Gianfranco Forte\n",
      "Enza Messina\n",
      "Fabio Antonio Stella\n",
      "Claudio Ferretti\n",
      "Marco Fattore\n",
      "Fulvia Pennoni\n",
      "Gianna Monti\n",
      "Fabio Mercorio\n",
      "Gabriele Gianini\n",
      "Davide Paolo Bernasconi\n",
      "Pier Giovanni Bissiri\n",
      "Marco Paganoni\n",
      "Simone Bianco\n",
      "Gianluca Della Vedova\n",
      "Mirko Cesarini\n",
      "Matteo Pelagatti\n",
      "Luca Presotto\n",
      "Gabriella Pasi\n"
     ]
    }
   ],
   "source": [
    "results = g.query(\"\"\"\n",
    "PREFIX ds: <http://example.org/ds#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT DISTINCT ?personName\n",
    "WHERE {\n",
    "  ?person a ds:Person ;\n",
    "          ds:teaches ?course ;\n",
    "          ds:fullName ?personName .\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "for row in results:\n",
    "    print(row.personName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 http://example.org/ds/paper/10.1016_j.jhep.2023.09.008 — 👨‍💼 Riccardo De Carlis\n",
      "📄 http://example.org/ds/paper/10.1016_j.jhep.2023.09.008 — 👨‍💼 Andrea Lauterio\n",
      "📄 http://example.org/ds/paper/10.1016_j.jhep.2023.09.008 — 👨‍💼 Davide Paolo Bernasconi\n",
      "📄 http://example.org/ds/paper/10.1016_j.jhep.2023.09.008 — 👨‍💼 C. Burcin Taner\n",
      "📄 http://example.org/ds/paper/10.3390_curroncol28060391 — 👨‍💼 Nicolò Tamini\n",
      "📄 http://example.org/ds/paper/10.3390_curroncol28060391 — 👨‍💼 Luca Gianotti\n",
      "📄 http://example.org/ds/paper/10.3390_curroncol28060391 — 👨‍💼 Davide Paolo Bernasconi\n",
      "📄 http://example.org/ds/paper/10.3390_cancers13071745 — 👨‍💼 Nicolò Tamini\n",
      "📄 http://example.org/ds/paper/10.3390_cancers13071745 — 👨‍💼 Davide Paolo Bernasconi\n",
      "📄 http://example.org/ds/paper/10.3390_cancers13071745 — 👨‍💼 Lorenzo Ripamonti\n"
     ]
    }
   ],
   "source": [
    "results = g.query(\"\"\"\n",
    "PREFIX ds: <http://example.org/ds#>\n",
    "SELECT DISTINCT ?paper ?authorName\n",
    "WHERE {\n",
    "  ?paper a ds:Paper ;\n",
    "         ds:hasAuthor ?author .\n",
    "  ?author ds:fullName ?authorName .\n",
    "}\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "for row in results:\n",
    "    print(f\"📄 {row.paper} — 👨‍💼 {row.authorName}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikidata ID: Q1073674\n",
      "Tripla:\n",
      "<https://openalex.org/I66752286> owl:sameAs <http://www.wikidata.org/entity/Q1073674 .\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# ID OpenAlex della Bicocca\n",
    "openalex_id = \"https://openalex.org/I66752286\"\n",
    "\n",
    "# Step 1: recupera i dati OpenAlex\n",
    "openalex_resp = requests.get(\"https://api.openalex.org/institutions/I66752286\")\n",
    "data = openalex_resp.json()\n",
    "\n",
    "# Step 2: prendi il ROR ID\n",
    "ror_uri = data.get(\"ror\")\n",
    "if not ror_uri:\n",
    "    print(\"Nessun ROR ID trovato.\")\n",
    "else:\n",
    "    ror_id = ror_uri.strip().split(\"/\")[-1]\n",
    "    ror_api_url = f\"https://api.ror.org/organizations/{ror_id}\"\n",
    "\n",
    "    # Step 3: chiama ROR API\n",
    "    ror_resp = requests.get(ror_api_url)\n",
    "    if ror_resp.status_code != 200:\n",
    "        print(\"Errore nella chiamata ROR:\", ror_resp.status_code)\n",
    "    else:\n",
    "        ror_data = ror_resp.json()\n",
    "        wikidata_ids = ror_data.get(\"external_ids\", {}).get(\"Wikidata\", {}).get(\"all\", [])\n",
    "        if wikidata_ids:\n",
    "            wikidata_id = wikidata_ids[0]\n",
    "            print(f\"Wikidata ID: {wikidata_id}\")\n",
    "            print(f\"Tripla:\")\n",
    "            print(f\"<{openalex_id}> owl:sameAs <http://www.wikidata.org/entity/{wikidata_id} .\")\n",
    "        else:\n",
    "            print(\"Nessun Wikidata ID trovato.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/institution/institutions.csv')\n",
    "\n",
    "\n",
    "# Funzione per ottenere Wikidata ID da OpenAlex → ROR → Wikidata\n",
    "def get_wikidata_id_from_openalex(openalex_url):\n",
    "    try:\n",
    "        # Estrai ID OpenAlex\n",
    "        openalex_id = openalex_url.split(\"/\")[-1]\n",
    "        openalex_resp = requests.get(f\"https://api.openalex.org/institutions/{openalex_id}\")\n",
    "        if openalex_resp.status_code != 200:\n",
    "            return None\n",
    "        data = openalex_resp.json()\n",
    "        ror_uri = data.get(\"ror\")\n",
    "        if not ror_uri:\n",
    "            return None\n",
    "        ror_id = ror_uri.strip().split(\"/\")[-1]\n",
    "        ror_resp = requests.get(f\"https://api.ror.org/organizations/{ror_id}\")\n",
    "        if ror_resp.status_code != 200:\n",
    "            return None\n",
    "        ror_data = ror_resp.json()\n",
    "        wikidata_ids = ror_data.get(\"external_ids\", {}).get(\"Wikidata\", {}).get(\"all\", [])\n",
    "        if wikidata_ids:\n",
    "            return f\"http://www.wikidata.org/entity/{wikidata_ids[0]}\"\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Applica la funzione a ogni riga\n",
    "df[\"wikidata_id\"] = df[\"ins_id\"].apply(get_wikidata_id_from_openalex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/institution/institutions_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ins_id</th>\n",
       "      <th>ins_name</th>\n",
       "      <th>ins_type</th>\n",
       "      <th>ins_country</th>\n",
       "      <th>wikidata_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/I4210110840</td>\n",
       "      <td>Azienda Ospedaliera San Gerardo</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://openalex.org/I4210153126</td>\n",
       "      <td>Istituti di Ricovero e Cura a Carattere Scient...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://openalex.org/I4210151645</td>\n",
       "      <td>Policlinico San Matteo Fondazione</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://openalex.org/I2277624104</td>\n",
       "      <td>Fondazione Bruno Kessler</td>\n",
       "      <td>funder</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://openalex.org/I4210139705</td>\n",
       "      <td>Ingegneria dei Sistemi (Italy)</td>\n",
       "      <td>company</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://openalex.org/I4210105192</td>\n",
       "      <td>United Institute of Informatics Problems</td>\n",
       "      <td>facility</td>\n",
       "      <td>BY</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>https://openalex.org/I4210117802</td>\n",
       "      <td>Institute of Electronics</td>\n",
       "      <td>nonprofit</td>\n",
       "      <td>BG</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://openalex.org/I4210125301</td>\n",
       "      <td>Health Awareness (United States)</td>\n",
       "      <td>company</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>https://openalex.org/I4210095629</td>\n",
       "      <td>Institute of Molecular Bioimaging and Physiology</td>\n",
       "      <td>facility</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>https://openalex.org/I4210116940</td>\n",
       "      <td>Don Carlo Gnocchi Foundation</td>\n",
       "      <td>nonprofit</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>https://openalex.org/I4210153325</td>\n",
       "      <td>Institute of Mathematical Statistics</td>\n",
       "      <td>other</td>\n",
       "      <td>US</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>https://openalex.org/I305386</td>\n",
       "      <td>Colgate-Palmolive (Switzerland)</td>\n",
       "      <td>funder</td>\n",
       "      <td>CH</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>https://openalex.org/I4210167034</td>\n",
       "      <td>Millennium Institute for Integrative Biology</td>\n",
       "      <td>other</td>\n",
       "      <td>CL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https://openalex.org/I4210109742</td>\n",
       "      <td>Shree Krishna Hospital</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>https://openalex.org/I4210127540</td>\n",
       "      <td>Nerviano Medical Sciences</td>\n",
       "      <td>company</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>https://openalex.org/I4210154278</td>\n",
       "      <td>Institute of Biomedical Technologies</td>\n",
       "      <td>facility</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>https://openalex.org/I4210135416</td>\n",
       "      <td>Ospedale di Parma</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ins_id  \\\n",
       "3    https://openalex.org/I4210110840   \n",
       "5    https://openalex.org/I4210153126   \n",
       "7    https://openalex.org/I4210151645   \n",
       "9    https://openalex.org/I2277624104   \n",
       "13   https://openalex.org/I4210139705   \n",
       "21   https://openalex.org/I4210105192   \n",
       "22   https://openalex.org/I4210117802   \n",
       "24                                NaN   \n",
       "37   https://openalex.org/I4210125301   \n",
       "62   https://openalex.org/I4210095629   \n",
       "63   https://openalex.org/I4210116940   \n",
       "64   https://openalex.org/I4210153325   \n",
       "68       https://openalex.org/I305386   \n",
       "82   https://openalex.org/I4210167034   \n",
       "84   https://openalex.org/I4210109742   \n",
       "102  https://openalex.org/I4210127540   \n",
       "106  https://openalex.org/I4210154278   \n",
       "111  https://openalex.org/I4210135416   \n",
       "\n",
       "                                              ins_name    ins_type  \\\n",
       "3                      Azienda Ospedaliera San Gerardo  healthcare   \n",
       "5    Istituti di Ricovero e Cura a Carattere Scient...  healthcare   \n",
       "7                    Policlinico San Matteo Fondazione  healthcare   \n",
       "9                             Fondazione Bruno Kessler      funder   \n",
       "13                      Ingegneria dei Sistemi (Italy)     company   \n",
       "21            United Institute of Informatics Problems    facility   \n",
       "22                            Institute of Electronics   nonprofit   \n",
       "24                                                 NaN         NaN   \n",
       "37                    Health Awareness (United States)     company   \n",
       "62    Institute of Molecular Bioimaging and Physiology    facility   \n",
       "63                        Don Carlo Gnocchi Foundation   nonprofit   \n",
       "64                Institute of Mathematical Statistics       other   \n",
       "68                     Colgate-Palmolive (Switzerland)      funder   \n",
       "82        Millennium Institute for Integrative Biology       other   \n",
       "84                              Shree Krishna Hospital  healthcare   \n",
       "102                          Nerviano Medical Sciences     company   \n",
       "106               Institute of Biomedical Technologies    facility   \n",
       "111                                  Ospedale di Parma  healthcare   \n",
       "\n",
       "    ins_country wikidata_id  \n",
       "3            IT        None  \n",
       "5            IT        None  \n",
       "7            IT        None  \n",
       "9            IT        None  \n",
       "13           IT        None  \n",
       "21           BY        None  \n",
       "22           BG        None  \n",
       "24          NaN        None  \n",
       "37           US        None  \n",
       "62           IT        None  \n",
       "63           IT        None  \n",
       "64           US        None  \n",
       "68           CH        None  \n",
       "82           CL        None  \n",
       "84           IN        None  \n",
       "102          IT        None  \n",
       "106          IT        None  \n",
       "111          IT        None  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"wikidata_id\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ins_id</th>\n",
       "      <th>ins_name</th>\n",
       "      <th>ins_type</th>\n",
       "      <th>ins_country</th>\n",
       "      <th>wikidata_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/I138689650</td>\n",
       "      <td>University of Padua</td>\n",
       "      <td>funder</td>\n",
       "      <td>IT</td>\n",
       "      <td>http://www.wikidata.org/entity/Q193510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/I4210094195</td>\n",
       "      <td>Azienda Socio Sanitaria Territoriale Grande Os...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>http://www.wikidata.org/entity/Q3886620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/I4210146710</td>\n",
       "      <td>Mayo Clinic in Florida</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>US</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6797499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/I4210110840</td>\n",
       "      <td>Azienda Ospedaliera San Gerardo</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>IT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/I66752286</td>\n",
       "      <td>University of Milano-Bicocca</td>\n",
       "      <td>funder</td>\n",
       "      <td>IT</td>\n",
       "      <td>http://www.wikidata.org/entity/Q1073674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>https://openalex.org/I108290504</td>\n",
       "      <td>University of Pisa</td>\n",
       "      <td>funder</td>\n",
       "      <td>IT</td>\n",
       "      <td>http://www.wikidata.org/entity/Q645663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>https://openalex.org/I4210156583</td>\n",
       "      <td>Laboratoire d'Informatique de Paris-Nord</td>\n",
       "      <td>facility</td>\n",
       "      <td>FR</td>\n",
       "      <td>http://www.wikidata.org/entity/Q3214424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>https://openalex.org/I135117807</td>\n",
       "      <td>Université de Sherbrooke</td>\n",
       "      <td>funder</td>\n",
       "      <td>CA</td>\n",
       "      <td>http://www.wikidata.org/entity/Q2579532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>https://openalex.org/I186771145</td>\n",
       "      <td>Covenant University</td>\n",
       "      <td>funder</td>\n",
       "      <td>NG</td>\n",
       "      <td>http://www.wikidata.org/entity/Q742241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>https://openalex.org/I60668342</td>\n",
       "      <td>University of Regensburg</td>\n",
       "      <td>funder</td>\n",
       "      <td>DE</td>\n",
       "      <td>http://www.wikidata.org/entity/Q574571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ins_id  \\\n",
       "0     https://openalex.org/I138689650   \n",
       "1    https://openalex.org/I4210094195   \n",
       "2    https://openalex.org/I4210146710   \n",
       "3    https://openalex.org/I4210110840   \n",
       "4      https://openalex.org/I66752286   \n",
       "..                                ...   \n",
       "122   https://openalex.org/I108290504   \n",
       "123  https://openalex.org/I4210156583   \n",
       "124   https://openalex.org/I135117807   \n",
       "125   https://openalex.org/I186771145   \n",
       "126    https://openalex.org/I60668342   \n",
       "\n",
       "                                              ins_name    ins_type  \\\n",
       "0                                  University of Padua      funder   \n",
       "1    Azienda Socio Sanitaria Territoriale Grande Os...  healthcare   \n",
       "2                               Mayo Clinic in Florida  healthcare   \n",
       "3                      Azienda Ospedaliera San Gerardo  healthcare   \n",
       "4                         University of Milano-Bicocca      funder   \n",
       "..                                                 ...         ...   \n",
       "122                                 University of Pisa      funder   \n",
       "123           Laboratoire d'Informatique de Paris-Nord    facility   \n",
       "124                           Université de Sherbrooke      funder   \n",
       "125                                Covenant University      funder   \n",
       "126                           University of Regensburg      funder   \n",
       "\n",
       "    ins_country                              wikidata_id  \n",
       "0            IT   http://www.wikidata.org/entity/Q193510  \n",
       "1            IT  http://www.wikidata.org/entity/Q3886620  \n",
       "2            US  http://www.wikidata.org/entity/Q6797499  \n",
       "3            IT                                     None  \n",
       "4            IT  http://www.wikidata.org/entity/Q1073674  \n",
       "..          ...                                      ...  \n",
       "122          IT   http://www.wikidata.org/entity/Q645663  \n",
       "123          FR  http://www.wikidata.org/entity/Q3214424  \n",
       "124          CA  http://www.wikidata.org/entity/Q2579532  \n",
       "125          NG   http://www.wikidata.org/entity/Q742241  \n",
       "126          DE   http://www.wikidata.org/entity/Q574571  \n",
       "\n",
       "[127 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "from rdflib.namespace import OWL\n",
    "import pandas as pd\n",
    "\n",
    "# Carica il dataset (modifica il percorso se necessario)\n",
    "df = pd.read_csv(\"../data/institution/institutions_wiki.csv\")\n",
    "\n",
    "# Inizializza il grafo RDF\n",
    "g \n",
    "\n",
    "# Aggiungi solo le triple owl:sameAs se wikidata_id è presente\n",
    "for _, row in df.iterrows():\n",
    "    wikidata_id = row.get(\"wikidata_id\")\n",
    "    if pd.notna(wikidata_id) and wikidata_id.strip() != \"\":\n",
    "        openalex_uri = URIRef(row[\"ins_id\"].strip())\n",
    "        wikidata_uri = URIRef(wikidata_id.strip())\n",
    "        g.add((openalex_uri, OWL.sameAs, wikidata_uri))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2022-01-01T00:00:00Z, Rank: 450, Method: QS World University Rankings\n",
      "Year: 2024-01-01T00:00:00Z, Rank: 481, Method: QS World University Rankings\n",
      "Year: 2025-01-01T00:00:00Z, Rank: 513, Method: QS World University Rankings\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?rank ?year ?rankingLabel\n",
    "WHERE {\n",
    "  wd:Q1073674 p:P1352 ?rankStatement .\n",
    "  ?rankStatement ps:P1352 ?rank .\n",
    "  ?rankStatement pq:P585 ?year .\n",
    "  ?rankStatement pq:P459 ?rankingMethod .\n",
    "  \n",
    "  ?rankingMethod rdfs:label ?rankingLabel .\n",
    "  FILTER(LANG(?rankingLabel) = \"en\")\n",
    "  FILTER(CONTAINS(?rankingLabel, \"QS\"))\n",
    "}\n",
    "ORDER BY ?year\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(f\"Year: {result['year']['value']}, Rank: {result['rank']['value']}, Method: {result['rankingLabel']['value']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Italy\n",
      "Administrative area: Milan\n",
      "Coordinates: Point(9.213344 45.518406)\n",
      "Address: Piazza dell'Ateneo Nuovo 1\n",
      "Postal code: N/A\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "SELECT ?countryLabel ?adminLabel ?coord ?address ?cap\n",
    "WHERE {\n",
    "  OPTIONAL { wd:Q1073674 wdt:P17 ?country . }\n",
    "  OPTIONAL { wd:Q1073674 wdt:P131 ?admin . }\n",
    "  OPTIONAL { wd:Q1073674 wdt:P625 ?coord . }\n",
    "  OPTIONAL { wd:Q1073674 wdt:P6375 ?address . }\n",
    "  OPTIONAL { wd:Q1073674 wdt:P281 ?cap . }\n",
    "\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    country = result.get(\"countryLabel\", {}).get(\"value\", \"N/A\")\n",
    "    admin = result.get(\"adminLabel\", {}).get(\"value\", \"N/A\")\n",
    "    coord = result.get(\"coord\", {}).get(\"value\", \"N/A\")\n",
    "    address = result.get(\"address\", {}).get(\"value\", \"N/A\")\n",
    "    cap = result.get(\"cap\", {}).get(\"value\", \"N/A\")\n",
    "\n",
    "    print(f\"Country: {country}\")\n",
    "    print(f\"Administrative area: {admin}\")\n",
    "    print(f\"Coordinates: {coord}\")\n",
    "    print(f\"Address: {address}\")\n",
    "    print(f\"Postal code: {cap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query con Aggiunta di wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 XAI for myo-controlled prosthesis: Explaining EMG data for hand gesture classification — URI: http://example.org/ds/paper/10.1016_j.knosys.2021.108053\n"
     ]
    }
   ],
   "source": [
    "q2 = \"\"\"\n",
    "PREFIX ds: <http://example.org/ds#>\n",
    "SELECT ?paper ?title\n",
    "WHERE {\n",
    "  ?author a ds:Author ;\n",
    "          ds:fullName ?name ;\n",
    "          ds:authored ?paper .\n",
    "  ?paper ds:hasTitle ?title .\n",
    "  FILTER(CONTAINS(LCASE(STR(?name)), \"noemi gozzi\"))\n",
    "}\n",
    "\"\"\"\n",
    "for row in g.query(q2):\n",
    "    print(f\"📄 {row.title} — URI: {row.paper}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Wikidata URI: http://www.wikidata.org/entity/Q689400\n"
     ]
    }
   ],
   "source": [
    "from rdflib.namespace import OWL\n",
    "\n",
    "# Query SPARQL per cercare \"ETH Zurich\" nel campo ds:institutionName\n",
    "query_eth = \"\"\"\n",
    "PREFIX ds: <http://example.org/ds#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "SELECT ?wikidata\n",
    "WHERE {\n",
    "  ?inst a ds:Institution ;\n",
    "        ds:institutionName ?name ;\n",
    "        owl:sameAs ?wikidata .\n",
    "  FILTER(CONTAINS(LCASE(STR(?name)), \"tu wien\"))\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "wikidata_uri = None\n",
    "for row in g.query(query_eth):\n",
    "    wikidata_uri = str(row.wikidata)\n",
    "    print(f\"🔗 Wikidata URI: {wikidata_uri}\")\n",
    "    break  # prende solo il primo risultato\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.wikidata.org/entity/Q11942'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📡 Interrogazione di Wikidata per Q689400 (QS Ranking)...\n",
      "📊 QS World University Rankings – Bicocca:\n",
      "🗓 2025 → 🏆 Rank: 190 (QS World University Rankings)\n",
      "🗓 2024 → 🏆 Rank: 184 (QS World University Rankings)\n",
      "🗓 2023 → 🏆 Rank: 179 (QS World University Rankings)\n",
      "🗓 2022 → 🏆 Rank: 180 (QS World University Rankings)\n",
      "🗓 2021 → 🏆 Rank: 191 (QS World University Rankings)\n",
      "🗓 2020 → 🏆 Rank: 192 (QS World University Rankings)\n",
      "🗓 2019 → 🏆 Rank: 199 (QS World University Rankings)\n",
      "🗓 2018 → 🏆 Rank: 182 (QS World University Rankings)\n",
      "🗓 2017 → 🏆 Rank: 183 (QS World University Rankings)\n",
      "🗓 2016 → 🏆 Rank: 197 (QS World University Rankings)\n",
      "🗓 2015 → 🏆 Rank: 246 (QS World University Rankings)\n",
      "🗓 2014 → 🏆 Rank: 264 (QS World University Rankings)\n",
      "🗓 2012 → 🏆 Rank: 274 (QS World University Rankings)\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "if wikidata_uri:\n",
    "    wikidata_id = wikidata_uri.split(\"/\")[-1]\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    sparql.setQuery(f\"\"\"\n",
    "    SELECT ?rank ?year ?rankingLabel\n",
    "    WHERE {{\n",
    "      wd:{wikidata_id} p:P1352 ?rankStatement .\n",
    "      ?rankStatement ps:P1352 ?rank .\n",
    "      ?rankStatement pq:P585 ?year .\n",
    "      \n",
    "    }}\n",
    "    ORDER BY DESC(?year)\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"📡 Interrogazione di Wikidata per {wikidata_id} (QS Ranking)...\")\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    print(\"📊 QS World University Rankings – Bicocca:\")\n",
    "    for res in results[\"results\"][\"bindings\"]:\n",
    "        year = res[\"year\"][\"value\"][:4]  # taglia a \"2025-01-01\" → \"2025\"\n",
    "        rank = res[\"rank\"][\"value\"]\n",
    "        \n",
    "        print(f\"🗓 {year} → 🏆 Rank: {rank} ({label})\")\n",
    "else:\n",
    "    print(\"❌ Nessun URI Wikidata trovato per 'Bicocca'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': {'vars': ['typeLabel', 'countryLabel']},\n",
       " 'results': {'bindings': [{'typeLabel': {'xml:lang': 'en',\n",
       "     'type': 'literal',\n",
       "     'value': 'university'},\n",
       "    'countryLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'Italy'}}]}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
